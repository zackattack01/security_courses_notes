# Usable Privacy
- Privacy is a kind of security, just less black and white
  - You might choose to share something with friends and friends of friends but not now exactly who this is
- Users should:
  - Be able to protect their information
  - Have the right to understand what happens with their data
  - Have as much control as possible over how it is used
- Analyzing usability is done in the same way with privacy as it is with security, so keep the user in mind first

### Privacy Policies
- Tell a user everything they need to know about how their data is collected and used
- They should provide all the information a user might need, but be written in a way that they understand
- They should be written in a natural sounding and understandable, accessible language
- Big blocks of texts can be overwhelming for users
- Should be, as usual, designed with the reader in mind (not with the lawyers protecting themselves in mind)

###### User Understanding
- Only about 16% of people say they read privacy policies all the tiime
- About half of these admit to not understanding them

###### Experiment- Percieved data access in Facebook apps
- Take this lollipop film
  - video collects information from your facebook profile and shows you a terrifying video 
- After guessing what data apps could access, users would either watch this video or read the privacy policy
- There was an increase in performance in both groups
- Video had hgher usability, it showed (quickly) what apps could access in a way users would remember

### Privacy Controls
- Say whether or not certain data should be collected
- Allows user to modify these permissions

### Informed consent by design
- Informed consent says users understand how data is collected and shared, and they consent to how it's used
- Six Components:
  - Disclosure: What information will be collected, who has access to it, where it will be archived, an for how long
  - Comprehension: Does the user actually understand what is being asked of them/ what will happen to their data
  - Voluntariness: Users aren't being forced or manipulated into sharing their data
  - Competence: In the U.S. children 12 and under can't give consent to share their data
  - Agreement: There needs to be an initial as well as ongoing agreement
  - Minimal Distraction: Giving info that will distract the user from what you're actually doing can inhibit them from giving informed consent
- Ex. gmail is voluntary because nothing is forcing a user to use this free service, and they are required to see the policy upon signing up.
- A website can disclose that you're on a secure connection with the lock and HTTPS, but this might not mean very much to the average user
- Can facebook run an experiment on people based on consent from one line about research in their policy?
  - People probably won't really understand what this means
  - People would not explicitly accept a psychological experiment being run on them
  - Since the only way for them to escape being subjected to these experiments would be to shut down their facebook, this becomes a form of coercion and is no longer voluntary

### 5 Pitfalls in Designing for Privacy 

###### Category I: Action
- Obscuring potential information flow
  - Information flow refers to:
    - Types of information
    - Kinds of observers
    - Type of media
    - Length of retention
    - Potential for unintended disclosure
    - Collection of metadata
  - Ex. google suggests adds based on content of your messages, but that content is never shared with anyone else, its only run through google's servers and compared to keywords

- Obscuring actual information flow
  - There is data that is stored or shared in a way that the user isn't aware of and can't do anything about

###### Category II: Action
- Emphasizing configuration over action
  - privacy management should be built into the natural workflow of users, not something that they need to think much about
- Lacking coarse-grained control
  - There should be a high level, top-level control where sharing can be turned on or off in an obvious way
  - On amazon there should be an easy way to turn off tracking of your searches to improve the way items are suggested for you
  - Think 'share with' followed by a select menu, should be quick and easy
- Inhibiting established practice
  - Think of what users will expect from other experiences and make the default behaviors match users' expectations
  - Problems come when more information is shared than what the user would have expected

### Inferring Personal Data
- Target sent targeted advertising to a girl for baby bottles, etc 2 weeks before she told her parents she was pregnant
- There are a number of behavioral patterns that occur that can predict attributes in very interesting ways
- Intelligent people like curly fries on facebook. Why?
- People become friends with other people that are like them. Certain likes can proliferate through a network of like-minded people
- Problem with changing how data is shared is that many social platforms main form of revenue comes from dealing with user's data in sometimes unethical ways
- We need to support scientists that want to give some of this power back to the users